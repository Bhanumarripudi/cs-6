# Surface EMG Based Hand Gesture Signal Classification Using CNN for Control of Software Robot  

### Project Supervisor:  
**Dr. Jaya Prakash Sahoo**  

### Cluster Name:  
**CS6**  

### Project Coordinator:  
**Dr. Ambar Bajpai**  

---

## Mini Project (PROJ2999) Outcomes  

1. **Real-Time Gesture-Based Control:**  
   Achieve real-time control of the software robot's movements and actions accurately with intuitive hand gestures. Improve the user experience while increasing accessibility.  

2. **Smooth Integration into Recognition Model:**  
   Utilize the surface EMG-based hand gesture recognition model with CNN and attention mechanisms to achieve accurate and reliable gesture interpretation. Reduce errors and improve system robustness.  

3. **Functional Robot Movements:**  
   Enable the robot to perform basic motions such as moving forward, backward, turning, or stopping. Implement predefined actions triggered by specific gestures to ease navigation and interaction in simulated environments.  

---

## Extended Project Abstract  

The development of a software robot controlled by a hand gesture recognition model is a modern approach to human-computer interaction. This project applies surface electromyography (sEMG) signals to interpret hand gestures, which are then translated into commands for robot control.  

The NinaPro dataset is used to train and test the model, providing a large and diverse dataset for robust gesture recognition. The system supports real-time gesture-based control with features including seamless integration of the recognition model and robot control logic. This ensures precise and responsive movements such as moving forward, turning, stopping, or executing task-specific actions.  

The attention mechanism implemented in the CNN model strengthens focus on critical signal regions, improving recognition accuracy and robustness under diverse conditions.  

This project showcases the feasibility of sEMG-based control systems and contributes to the increasing demand for adaptive and intelligent robotic solutions that enhance user experience and accessibility in real-world scenarios.  

---

## Extended Project Objectives  

1. Develop a robust hand gesture recognition model using surface EMG signals, leveraging CNN with an attention mechanism for accurate classification.  
2. Design a software robot capable of performing real-time actions based on recognized hand gestures.  
3. Ensure system adaptability and usability across different users by accommodating variations in sEMG signal patterns.  
4. Evaluate the overall performance in terms of accuracy, reliability, and responsiveness under diverse conditions.  

---

## Gantt Chart for Extended Project (PROJ3999)  

*## Gantt Chart for Extended Project (PROJ3999)

| Task                             | Duration      | Start Date | End Date   | Milestone                     |
|----------------------------------|---------------|------------|------------|--------------------------------|
| Literature Review and Research   | 2 weeks       | 01/01/2025 | 14/01/2025 | Selection of Dataset and Model |
| Dataset Preprocessing            | 3 weeks       | 15/01/2025 | 04/02/2025 | Clean and Prepare Dataset     |
| Model Development (CNN + Attention)| 4 weeks      | 05/02/2025 | 03/03/2025 | Implement and Train Model     |
| Model Evaluation and Optimization| 3 weeks       | 04/03/2025 | 24/03/2025 | Achieve Target Accuracy       |
| Integration with Robot Control   | 2 weeks       | 25/03/2025 | 07/04/2025 | Gesture-Controlled Actions    |
| System Testing and Validation    | 2 weeks       | 08/04/2025 | 21/04/2025 | Performance Testing           |
| Documentation and Final Report   | 1 week        | 22/04/2025 | 28/04/2025 | Submit Final Report           |
| Final Presentation               | 1 week        | 29/04/2025 | 05/05/2025 | Project Presentation          |
*  

---

## Suggested IEEE Conference Targets  

1. **IEEE International Conference on Emerging Smart Computing & Informatics 2025**  
2. **IEEE International Conference on Intelligent and Cloud Computing (ICoICC) 2025**  

